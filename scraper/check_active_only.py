#!/usr/bin/env python3
"""Check only currently active recruitments."""

import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re

def check_active_recruitments():
    """Check only active recruitments with detailed analysis."""
    url = "https://www.amed.go.jp/koubo/koubo_index.html"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; ResearchBot/1.0; +https://theta-tech.co.jp/bot)",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, "lxml")
        
        # Find main content area
        content = soup.get_text()
        
        # Find the "çµ‚äº†ã—ãŸå…¬å‹Ÿ" marker position
        ended_marker = content.find("çµ‚äº†ã—ãŸå…¬å‹Ÿ")
        if ended_marker == -1:
            print("è­¦å‘Š: 'çµ‚äº†ã—ãŸå…¬å‹Ÿ'ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            ended_marker = len(content)  # Use full content
        
        # Extract only the active section
        active_section_text = content[:ended_marker]
        
        # Create a new soup with only active section
        active_soup = BeautifulSoup(response.text, "lxml")
        
        # Find all links
        all_links = active_soup.select("a[href*='/koubo/']")
        
        active_recruitments = []
        
        for link in all_links:
            href = link.get('href', '')
            text = link.get_text(strip=True)
            
            # Skip if not a recruitment link
            if not text or len(text) < 10 or not 'ä»¤å’Œ' in text:
                continue
            
            # Skip if it's an index or search page
            if any(skip in href for skip in ['index', 'search', 'help']):
                continue
            
            # Check if this link appears in active section
            if text in active_section_text:
                # Extract deadline
                parent_text = ""
                if link.parent:
                    parent_text = link.parent.get_text()
                
                # Look for deadline in various formats
                deadline = None
                deadline_patterns = [
                    r"ç· åˆ‡[ï¼š:]\s*ä»¤å’Œ(\d+)å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥",
                    r"å…¬å‹Ÿç· åˆ‡[ï¼š:]\s*ä»¤å’Œ(\d+)å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥",
                    r"å¿œå‹Ÿç· åˆ‡[ï¼š:]\s*ä»¤å’Œ(\d+)å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥",
                    r"ä»¤å’Œ(\d+)å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥.*ç· åˆ‡",
                ]
                
                for pattern in deadline_patterns:
                    match = re.search(pattern, parent_text)
                    if match:
                        year = 2018 + int(match.group(1))
                        month = int(match.group(2))
                        day = int(match.group(3))
                        deadline = f"{year}å¹´{month}æœˆ{day}æ—¥"
                        break
                
                # Check if international
                intl_keywords = ["å›½éš›", "æµ·å¤–", "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "ASPIRE", "SICORP", 
                               "e-ASIA", "Interstellar", "æ—¥ç±³", "æ—¥ãƒ»", "å¤–å›½"]
                is_international = any(kw in text for kw in intl_keywords)
                
                active_recruitments.append({
                    'title': text,
                    'url': f"https://www.amed.go.jp{href}" if href.startswith('/') else href,
                    'deadline': deadline,
                    'is_international': is_international,
                    'keywords': [kw for kw in intl_keywords if kw in text]
                })
        
        # Print results
        print("ğŸ” AMEDç¾åœ¨å‹Ÿé›†ä¸­ã®å…¬å‹Ÿï¼ˆè©³ç´°åˆ†æï¼‰")
        print("=" * 70)
        print(f"ğŸ“Š ç¾åœ¨å‹Ÿé›†ä¸­ã®ç·æ•°: {len(active_recruitments)}ä»¶")
        
        intl_count = sum(1 for r in active_recruitments if r['is_international'])
        print(f"ğŸŒ å›½éš›ç ”ç©¶: {intl_count}ä»¶ ({intl_count/len(active_recruitments)*100:.1f}%)" if active_recruitments else "0ä»¶")
        
        print("\nğŸ“‹ å‹Ÿé›†ä¸­ã®å…¨å…¬å‹Ÿãƒªã‚¹ãƒˆ:")
        for i, recruit in enumerate(active_recruitments, 1):
            print(f"\n{i}. {recruit['title'][:80]}...")
            print(f"   ç· åˆ‡: {recruit['deadline'] or 'ä¸æ˜'}")
            print(f"   å›½éš›: {'âœ“' if recruit['is_international'] else 'âœ—'}")
            if recruit['is_international']:
                print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(recruit['keywords'])}")
            print(f"   URL: {recruit['url']}")
        
        print("\nğŸŒ å›½éš›ç ”ç©¶ã®ã¿:")
        intl_recruits = [r for r in active_recruitments if r['is_international']]
        for i, recruit in enumerate(intl_recruits, 1):
            print(f"\n{i}. {recruit['title'][:100]}...")
            print(f"   ç· åˆ‡: {recruit['deadline'] or 'ä¸æ˜'}")
            print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(recruit['keywords'])}")
        
        return active_recruitments
        
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        return []

if __name__ == "__main__":
    check_active_recruitments()