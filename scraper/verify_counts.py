#!/usr/bin/env python3
"""Verify the actual counts of AMED recruitment data."""

import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re
from collections import defaultdict

def verify_amed_counts():
    """Verify actual counts and status of AMED recruitments."""
    url = "https://www.amed.go.jp/koubo/koubo_index.html"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; ResearchBot/1.0; +https://theta-tech.co.jp/bot)",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, "lxml")
        full_text = soup.get_text()
        
        # Analysis results
        results = {
            'total_links': 0,
            'active_recruitments': 0,
            'ended_recruitments': 0,
            'international_active': 0,
            'international_ended': 0,
            'international_keywords_found': defaultdict(int),
            'date_analysis': {
                'future_deadlines': 0,
                'past_deadlines': 0,
                'no_deadline': 0
            }
        }
        
        # International keywords
        intl_keywords = [
            "å›½éš›å…±åŒ", "å¤–å›½äºº", "å¤šå›½ç±", "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "æµ·å¤–", "å›½éš›",
            "ASPIRE", "e-ASIA", "SICORP", "Interstellar",
            "æ—¥ç±³", "æ—¥æ¬§", "æ—¥ä¸­", "æ—¥éŸ“", "æ—¥å°", "æ—¥ãƒ»ã‚«ãƒŠãƒ€", "æ—¥ãƒ»ã‚¹ã‚¤ã‚¹",
            "æ—¥ãƒ»è‹±å›½", "æ—¥ãƒ»ãƒ•ãƒ©ãƒ³ã‚¹", "æ—¥ãƒ»ãƒ‰ã‚¤ãƒ„", "æ—¥ãƒ»ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢"
        ]
        
        # Find all recruitment links
        all_links = soup.select("a[href*='/koubo/']")
        
        # Separate sections
        sections = {
            'active': [],
            'ended': []
        }
        
        # Try to identify sections
        current_section = 'unknown'
        
        # Look for section markers
        if "çµ‚äº†ã—ãŸå…¬å‹Ÿ" in full_text:
            # Find position of "çµ‚äº†ã—ãŸå…¬å‹Ÿ"
            ended_marker = full_text.find("çµ‚äº†ã—ãŸå…¬å‹Ÿ")
            
            for link in all_links:
                href = link.get('href', '')
                text = link.get_text(strip=True)
                
                if not text or len(text) < 10 or not 'ä»¤å’Œ' in text:
                    continue
                
                # Get position in page
                link_text_pos = full_text.find(text)
                
                if link_text_pos > 0:
                    if link_text_pos < ended_marker:
                        sections['active'].append((link, text))
                    else:
                        sections['ended'].append((link, text))
        else:
            # If no clear section markers, check dates
            for link in all_links:
                href = link.get('href', '')
                text = link.get_text(strip=True)
                
                if not text or len(text) < 10 or not 'ä»¤å’Œ' in text:
                    continue
                
                # Check if deadline is mentioned
                deadline_match = re.search(r"ä»¤å’Œ(\d+)å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥", text)
                if deadline_match:
                    year = 2018 + int(deadline_match.group(1))
                    month = int(deadline_match.group(2))
                    day = int(deadline_match.group(3))
                    
                    try:
                        deadline_date = datetime(year, month, day)
                        if deadline_date > datetime.now():
                            sections['active'].append((link, text))
                            results['date_analysis']['future_deadlines'] += 1
                        else:
                            sections['ended'].append((link, text))
                            results['date_analysis']['past_deadlines'] += 1
                    except:
                        results['date_analysis']['no_deadline'] += 1
                else:
                    results['date_analysis']['no_deadline'] += 1
        
        # Count results
        results['active_recruitments'] = len(sections['active'])
        results['ended_recruitments'] = len(sections['ended'])
        results['total_links'] = len(sections['active']) + len(sections['ended'])
        
        # Check international keywords
        for section_name, links in sections.items():
            for link, text in links:
                for keyword in intl_keywords:
                    if keyword in text:
                        results['international_keywords_found'][keyword] += 1
                        if section_name == 'active':
                            results['international_active'] += 1
                        else:
                            results['international_ended'] += 1
                        break  # Count each link only once
        
        # Print detailed results
        print("ğŸ” AMEDå…¬å‹Ÿæƒ…å ±æ¤œè¨¼çµæœ")
        print("=" * 50)
        print(f"ğŸ“Š ç·ãƒªãƒ³ã‚¯æ•°: {results['total_links']}")
        print(f"âœ… ç¾åœ¨å‹Ÿé›†ä¸­: {results['active_recruitments']}")
        print(f"âŒ å‹Ÿé›†çµ‚äº†: {results['ended_recruitments']}")
        print()
        
        print("ğŸŒ å›½éš›ç ”ç©¶é–¢é€£")
        print(f"ç¾åœ¨å‹Ÿé›†ä¸­ã®å›½éš›ç ”ç©¶: {results['international_active']}")
        print(f"å‹Ÿé›†çµ‚äº†ã®å›½éš›ç ”ç©¶: {results['international_ended']}")
        print(f"å›½éš›ç ”ç©¶ç‡ï¼ˆå…¨ä½“ï¼‰: {(results['international_active'] + results['international_ended']) / results['total_links'] * 100:.1f}%")
        print(f"å›½éš›ç ”ç©¶ç‡ï¼ˆå‹Ÿé›†ä¸­ï¼‰: {results['international_active'] / results['active_recruitments'] * 100:.1f}%" if results['active_recruitments'] > 0 else "N/A")
        print()
        
        print("ğŸ“… ç· åˆ‡æ—¥åˆ†æ")
        print(f"å°†æ¥ã®ç· åˆ‡: {results['date_analysis']['future_deadlines']}")
        print(f"éå»ã®ç· åˆ‡: {results['date_analysis']['past_deadlines']}")
        print(f"ç· åˆ‡ä¸æ˜: {results['date_analysis']['no_deadline']}")
        print()
        
        print("ğŸ”¤ æ¤œå‡ºã•ã‚ŒãŸå›½éš›ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¸Šä½ï¼‰")
        sorted_keywords = sorted(results['international_keywords_found'].items(), 
                               key=lambda x: x[1], reverse=True)[:10]
        for keyword, count in sorted_keywords:
            print(f"  {keyword}: {count}å›")
        
        # Show sample active international studies
        print("\nğŸ“Œ ç¾åœ¨å‹Ÿé›†ä¸­ã®å›½éš›ç ”ç©¶ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰")
        count = 0
        for link, text in sections['active']:
            for keyword in intl_keywords:
                if keyword in text:
                    print(f"{count+1}. {text[:80]}...")
                    count += 1
                    break
            if count >= 5:
                break
        
        return results
        
    except Exception as e:
        print(f"Error: {e}")
        return None

if __name__ == "__main__":
    verify_amed_counts()